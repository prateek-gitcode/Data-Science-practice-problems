library(tm)
library(topicmodels)
library(slam)
install.packages('tm')
library(tm)
library(topicmodels)
install.packages('topicmodels')
install.packages(slam)
install.packages('slam')
install.packages("slam")
library(tm)
install.packages('NLP')
install.packages("NLP")
library(tm)
library(topicmodels)
library(slam)
x <- readLines(file.choose()) #import modi.txt file
x
length(x)
#using tm package#
mydata.corpus <- Corpus(VectorSource(x))
mydata.corpus <- tm_map(mydata.corpus,removePunctuation)
my_stopwords <- readLines(file.choose())
mydata.corpus <- tm_map(mydata.corpus,removeWords,my_stopwords)
mydata.corpus <- tm_map(mydata.corpus,removeNumbers)
mydata.corpus <- tm_map(mydata.corpus,stripWhitespace)
#build a term document matrix
mydata.dtm3 <- TermDocumentMatrix(mydata.corpus)
as.matrix(mydata.dtm3)
dim(mydata.dtm3)
dtm <- t(mydata.dtm3)
as.matrix(dtm)
dtm$ncol
dtm$nrow
rowTotals <- apply(dtm,1,sum)
dtm.new <- dtm[rowTotals>0,]
lda <- LDA(dtm.new,10)
lterm <- terms(lda,10)
lterm
tops <- terms(lda)
tb <- table(names(tops),unlist(tops))
tb <- as.data.frame.matrix(tb)
cls <- hclust(dist(tb),method = 'ward.D2')
par(family ='HiraKakuProN-W3')
plot(cls)
library(syuzhet)
setwd("D:/Data science materials/Assignments/Text Mining")
library(rvest)
library(XML)
library(magrittr)
install.packages('rvest')
install.packages('XML')
library(rvest)
library(XML)
library(magrittr)
# Amazon Reviews #############################
aurl <- "https://www.amazon.in/Redmi-Note-Pro-Gamma-Storage/product-reviews/B07X1KSLBV/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber"
amazon_reviews <- NULL
for (i in 1:20){
murl <- read_html(as.character(paste(aurl,i,sep="=")))
rev <- murl %>%
html_nodes(".review-text") %>%
html_text()
amazon_reviews <- c(amazon_reviews,rev)
}
write.table(amazon_reviews,"reviews.txt")
#Performing Sentimental Analysis
s_v <- vector()
library(syuzhet)
install.packages('syuzhet')
library(syuzhet)
for ( i in 1:200)
s_v[i] <- as.character(amazon_reviews[i,])
class(s_v)
str(s_v)
head(s_v)
sentiment_vector <- get_sentiment(s_v,method = "bing")
head(sentiment_vector)
nrc_vector <- get_sentiment(s_v,method = "nrc")
head(nrc_vector)
sum(sentiment_vector)
mean(sentiment_vector)
summary(sentiment_vector)
#plot
plot(sentiment_vector,type = "l", main = "Plot Trajectory",
xlab = "Narrative Time", ylab = "Emotional Valence")
abline(h= 0, col= "red")
#to extract the sentance with most negative emotional valence
negative <- s_v[which.min(sentiment_vector)]
negative
# and to extract most positive sentence
positive <- s_v[which.max(sentiment_vector)]
positive
#more depth
poa_v <- s_v
poa_sent <- get_sentiment(poa_v, method = "bing")
plot(poa_sent,type = "h", main = "LOTR using transformed Values",
xlab = "Narrative Time", ylab = "Emotinal Valence")
View(murl)
library(rvest)
library(XML)
library(magrittr)
# Amazon Reviews #############################
aurl <- "https://www.amazon.in/Redmi-Note-Pro-Gamma-Storage/product-reviews/B07X1KSLBV/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber"
amazon_reviews <- NULL
for (i in 1:20){
murl <- read_html(as.character(paste(aurl,i,sep="=")))
rev <- murl %>%
html_nodes(".review-text") %>%
html_text()
amazon_reviews <- c(amazon_reviews,rev)
}
setwd("D:/Data science materials/Assignments/Text Mining")
